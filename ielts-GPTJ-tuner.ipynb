{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/minhthonglai/ielts-gptj-tuner?scriptVersionId=242608378\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# GPT-J Fine-tuning for Essay Scoring","metadata":{}},{"cell_type":"markdown","source":"## Global Setting Variables","metadata":{}},{"cell_type":"code","source":"MODEL_PATH = 'models/'\nDATA_PATH = 'data/'\nRANDOM_SEED = 42 # Set to `None` for the generator uses the current system time.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:38:15.74017Z","iopub.execute_input":"2025-05-29T19:38:15.740593Z","iopub.status.idle":"2025-05-29T19:38:15.746849Z","shell.execute_reply.started":"2025-05-29T19:38:15.74055Z","shell.execute_reply":"2025-05-29T19:38:15.745609Z"}},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":"## System configurations ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when create a version using \"Save & Run All\" \n# Can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport sys\nimport os\n\n# Check Python version\nprint(f\"Python Version: `{sys.version}`\")  # Detailed version info\nprint(f\"Base Python location: `{sys.base_prefix}`\")\nprint(f\"Current Environment location: `{os.path.basename(sys.prefix)}`\", end='\\n\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:55:53.758234Z","iopub.execute_input":"2025-05-29T18:55:53.759226Z","iopub.status.idle":"2025-05-29T18:55:53.773659Z","shell.execute_reply.started":"2025-05-29T18:55:53.759173Z","shell.execute_reply":"2025-05-29T18:55:53.771397Z"}},"outputs":[{"name":"stdout","text":"Python Version: `3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]`\nBase Python location: `/usr`\nCurrent Environment location: `usr`\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport time  # for CPU timing\n\n# Check if GPU is available and being used\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"Current device: {torch.cuda.current_device()}\")\n    print(f\"Device name: {torch.cuda.get_device_name()}\")\n    print(f\"Device memory: {torch.cuda.get_device_properties(0).total_memory / 1e9} GB\")\n\n# This code will work in both CPU and GPU environments\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n    \n# Test with a simple operation - modified to work on both CPU and GPU\nx = torch.rand(10000, 10000, device=device)\ny = torch.rand(10000, 10000, device=device)\n\nif device.type == \"cuda\":\n    # GPU timing approach\n    start = torch.cuda.Event(enable_timing=True)\n    end = torch.cuda.Event(enable_timing=True)\n    start.record()\n    z = x @ y  # Matrix multiplication\n    end.record()\n    torch.cuda.synchronize()\n    print(f\"Operation time: {start.elapsed_time(end)} ms\")\nelse:\n    # CPU timing approach\n    start_time = time.time()\n    z = x @ y  # Matrix multiplication\n    end_time = time.time()\n    print(f\"Operation time: {(end_time - start_time) * 1000} ms\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:55:53.775721Z","iopub.execute_input":"2025-05-29T18:55:53.776208Z","iopub.status.idle":"2025-05-29T18:56:15.999746Z","shell.execute_reply.started":"2025-05-29T18:55:53.776151Z","shell.execute_reply":"2025-05-29T18:56:15.998797Z"}},"outputs":[{"name":"stdout","text":"CUDA available: False\nUsing device: cpu\nOperation time: 14637.798309326172 ms\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Install required libraries","metadata":{}},{"cell_type":"code","source":"# %pip install transformers peft datasets accelerate bitsandbytes trl\n# %pip install sentencepiece","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:56:16.001357Z","iopub.execute_input":"2025-05-29T18:56:16.001776Z","iopub.status.idle":"2025-05-29T18:56:16.005589Z","shell.execute_reply.started":"2025-05-29T18:56:16.001743Z","shell.execute_reply":"2025-05-29T18:56:16.004638Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Import Libraries and Set Configuration","metadata":{}},{"cell_type":"code","source":"import torch\nimport transformers\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, DataCollatorForLanguageModeling\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nfrom datasets import load_dataset\n\nimport os\nimport re\nimport matplotlib.pyplot as plt\n\n# Check if GPU is available\nif torch.cuda.is_available():\n    print(\"GPU is available. Setting up GPU environment...\")\n    # Set maximum GPU memory usage to avoid OOM errors\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n    torch.cuda.empty_cache()\nelse:\n    print(\"No GPU detected. Running in CPU-only mode.\")\n    # Ensure CUDA is disabled\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n\n# Enable memory efficient attention - works for both CPU and GPU\nos.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"  # Work offline if model is downloaded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:56:16.006511Z","iopub.execute_input":"2025-05-29T18:56:16.006838Z","iopub.status.idle":"2025-05-29T18:56:49.022347Z","shell.execute_reply.started":"2025-05-29T18:56:16.006812Z","shell.execute_reply":"2025-05-29T18:56:49.021414Z"}},"outputs":[{"name":"stderr","text":"2025-05-29 18:56:29.093182: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748544989.343242      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748544989.414677      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"No GPU detected. Running in CPU-only mode.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Prepare the IELTS Dataset","metadata":{}},{"cell_type":"markdown","source":"### Sample code to create a dataset for IELTS assessment\n","metadata":{}},{"cell_type":"markdown","source":"Need to prepare the dataset with this structure:\n\n```\nData format structure:\n\ndata = {\n  \"input\": [\n    \"\"\"Rate this IELTS essay:\n\nTopic: [topic essay text]\n\nEssay: [student essay text]\"\"\", ...\n    ],\n\n  \"output\": [\n    \"\"\"Task Achievement: [band score] - [detailed feedback]\n\nCoherence and Cohesion: [band score] - [detailed feedback]\n\nLexical Resource: [band score] - [detailed feedback]\n\nGrammatical Range and Accuracy: [band score] - [detailed feedback]\n\nOverall Band Score: [band score]\"\"\", ...\n    ]\n}\n```","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset\n\n# Comprehensive example data for IELTS assessment across different levels\ndata = {\n    \"input\": [\n        # Low Band Example (5.0-5.5)\n        \"\"\"Rate this IELTS essay: \n\nTopic: Some people think that governments should spend money on building train and subway lines to reduce traffic congestion. Others think that building more and wider roads is the better way to reduce traffic congestion. Discuss both views and give your opinion.\n\nEssay:\nToday traffic is big problem in many city in the world. Some people say government need to build train and subway to fix this problem. Other people think making more road is better solution. I will discuss both idea and give my opinion.\n\nFirst, making train and subway is good idea because many people can travel together. If 100 people go in one train, it means maybe 50 cars are not in road. Also train and subway don't need parking place in city center. Many cars need parking and this take a lot of space in city. Train also more cheap for people who travel every day to work.\n\nSecond idea is making more roads and wider roads for cars. This is also good because many people like to drive own car. It is comfortable and private. You can go anywhere you want with car but train only go to some station. Also with car you can carry many things like shopping or luggage.\n\nIn my opinion, I think train and subway is better solution for big city. Because many cars make pollution and noise. Also train is faster in busy time because no traffic jam for train. But car is still necessary for some people. So government should make good public transport and also some road, but not too many road.\n\nIn conclusion, I believe that government should spend more money for train and subway, but also make some road for car. But train is better solution for traffic problem and environment.\n\"\"\",\n\n        # Mid Band Example (6.5)\n        \"\"\"Rate this IELTS essay: \n\nTopic: Some people believe that unpaid community service should be a compulsory part of high school programs. To what extent do you agree or disagree?\n\nEssay:\nThere is growing debate regarding whether community service should be mandatory for high school students. While some argue that such requirements promote civic responsibility and personal development, others contend that forced volunteerism contradicts the very nature of community service. In my opinion, I partially agree that community service should be incorporated into high school curricula, but with certain limitations.\n\nMandatory community service offers several advantages for student development. Primarily, it exposes young people to social issues they might otherwise remain unaware of, fostering empathy and social consciousness. For instance, students volunteering at homeless shelters or food banks gain firsthand understanding of poverty and inequality in their communities. Moreover, these experiences help develop soft skills such as teamwork, communication, and leadership that are valuable for future academic and professional pursuits. Research has demonstrated that students who participate in community service often show improved academic performance and higher rates of civic engagement later in life.\n\nHowever, forcing students to volunteer presents significant drawbacks. The compulsory nature of such programs may generate resentment and undermine the intrinsic value of helping others. When students participate reluctantly, the quality of their service suffers, potentially creating negative experiences for both the students and the communities they serve. Additionally, some students already face considerable academic pressure and family responsibilities, and mandatory service requirements might impose undue burden on their limited time.\n\nA balanced approach would involve integrating community service opportunities into the curriculum without strict hourly requirements. Schools could offer a variety of service options aligned with different courses, allowing students to choose activities that match their interests and schedules. This approach would preserve the educational benefits while respecting student autonomy and different life circumstances.\n\nIn conclusion, while I believe in the value of community service as part of education, I think schools should encourage rather than mandate participation. Providing structured opportunities and recognition for voluntary service would better foster genuine civic engagement than compulsory requirements.\n\"\"\",\n\n        # High Band Example (8.0-8.5)\n        \"\"\"Rate this IELTS essay: \n\nTopic: Some people believe that visitors to other countries should follow local customs and behavior. Others disagree and think that the host country should welcome cultural differences. Discuss both these views and give your own opinion.\n\nEssay:\nThe question of whether international visitors should adapt to local customs or maintain their own cultural practices when abroad represents a nuanced cultural and ethical dilemma. While there are compelling arguments for both cultural adaptation and preservation of diversity, this essay will analyze both perspectives before presenting a balanced position.\n\nProponents of cultural adaptation emphasize that adopting local customs demonstrates respect for the host society. When visitors make concerted efforts to observe indigenous practices, from removing shoes before entering homes in Japan to maintaining appropriate attire in religious sites across the Middle East, they acknowledge the values underpinning these traditions. This respectful approach facilitates meaningful cross-cultural engagement and mitigates potential misunderstandings or offense. Furthermore, embracing local customs offers visitors authentic insights into different worldviews and social structures that might otherwise remain inaccessible, thereby enriching their international experience.\n\nConversely, advocates for cultural diversity contend that globalization's value lies precisely in the exchange of varied perspectives and practices. They argue that host countries benefit immensely from exposure to different cultural expressions, from cuisine and art to social customs and business practices. Many thriving metropolitan centers like London, New York, and Singapore attribute their dynamism and innovation to their multicultural character. From this viewpoint, expecting visitors to abandon their cultural identity represents a lost opportunity for mutual enrichment and contradicts principles of individual expression and authenticity.\n\nIn reconciling these positions, it becomes evident that context and degree are paramount considerations. Certain fundamental legal and ethical norms must be respected regardless of cultural background. However, beyond these essential boundaries, a thoughtful balance can be achieved. Visitors should make reasonable efforts to understand and respect core local values and practices, particularly in settings where certain behaviors may cause genuine offense or disruption. Simultaneously, host societies benefit from cultivating openness toward cultural differences in areas where diversity poses no significant social harm.\n\nIn conclusion, while visitors should demonstrate cultural sensitivity by observing fundamental local customs, particularly in more conservative or traditional settings, host countries equally benefit from embracing reasonable cultural differences. This balanced approach fosters authentic cross-cultural understanding while preserving the rich tapestry of global cultural heritage. The most meaningful international exchanges occur when mutual respect allows both adaptation and diversity to coexist.\n\"\"\"\n    ],\n    \n    \"output\": [\n        # Low Band Score (5.5)\n        \"\"\"Task Achievement: 5.0 - The essay addresses both views but development of ideas is limited. entries are mostly general rather than specific and some parts of the task receive inadequate attention.\n\nCoherence and Cohesion: 5.0 - The writing is organized with some use of paragraphing and basic linking words, but the overall progression of ideas lacks sophistication. There are some lapses in cohesion and the conclusion partially repeats rather than fully summarizing.\n\nLexical Resource: 5.0 - Uses a limited range of vocabulary with some attempt at more complex items but with noticeable errors. Word choice is sometimes inaccurate and repetitive. Spelling and word formation errors are evident but don't significantly impede communication.\n\nGrammatical Range and Accuracy: 5.5 - Uses a mix of simple and complex sentence forms but with frequent grammatical errors. Article usage, subject-verb agreement, and plural forms contain systematic errors. Control of tense and sentence structure is inconsistent.\n\nOverall Band Score: 5.0\"\"\",\n        \n        # Mid Band Score (6.5)\n        \"\"\"Task Achievement: 7.0 - The essay addresses all parts of the task. The writer's position is clear and consistent throughout. Ideas are extended and supported, though some supporting arguments could be more fully developed with specific examples.\n\nCoherence and Cohesion: 6.5 - Information and ideas are generally arranged coherently with clear overall progression. Paragraphing is logical and each paragraph has a clear central topic. Cohesive devices are used effectively, though sometimes mechanical.\n\nLexical Resource: 6.5 - Uses an adequate range of vocabulary for the task with some evidence of flexibility. There are attempts to use less common vocabulary though occasionally with some awkwardness. Word form errors are minimal and do not impede communication.\n\nGrammatical Range and Accuracy: 6.5 - Uses a mix of simple and complex sentence forms. Most sentences are error-free but there are some mistakes in more complex structures. Grammar and punctuation are generally well-controlled though with occasional inconsistencies.\n\nOverall Band Score: 6.5\"\"\",\n        \n        # High Band Score (8.0)\n        \"\"\"Task Achievement: 9.0 - The essay fully addresses all parts of the task with a sophisticated exploration of both perspectives. The position is clear and consistent with a nuanced examination of the complexities involved. Ideas are well-developed, relevant, and convincingly supported.\n\nCoherence and Cohesion: 8.5 - Information and ideas are skillfully organized with logical sequencing and clear progression. Paragraphing is consistently appropriate with each paragraph expertly developing a distinct aspect. A wide range of cohesive devices is used with high accuracy and flexibility.\n\nLexical Resource: 8.0 - Uses a wide vocabulary resource precisely and flexibly to convey precise meaning. There is sophisticated control of lexical features with very rare minor errors only in uncommon words. Skillful use of appropriate register and style.\n\nGrammatical Range and Accuracy: 8.0 - Uses a wide range of structures with flexibility and accuracy. The majority of sentences are error-free with only very occasional minor errors. Demonstrates sophisticated control of grammar and punctuation across complex structures.\n\nOverall Band Score: 8.0\"\"\"\n    ]\n}\n\n# Create dataset from your dictionary\ndataset = Dataset.from_dict(data)\nprint(f\"Dataset created with {len(dataset)} entries\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:27:44.8573Z","iopub.execute_input":"2025-05-29T19:27:44.857765Z","iopub.status.idle":"2025-05-29T19:27:44.882331Z","shell.execute_reply.started":"2025-05-29T19:27:44.857732Z","shell.execute_reply":"2025-05-29T19:27:44.881136Z"}},"outputs":[{"name":"stdout","text":"Dataset created with 3 entries\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"### Split dataset","metadata":{}},{"cell_type":"code","source":"# Use train_test_split for cleaner splitting\nsplit_dataset = dataset.train_test_split(test_size=0.1, seed=RANDOM_SEED)\n\ntrain_dataset = split_dataset['train'] # 90% for training\ntest_dataset = split_dataset['test'] # 10% for testing\n\nprint(f\"Training entries: {len(train_dataset)}\")\nprint(f\"Testing entries: {len(test_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:48:47.065321Z","iopub.execute_input":"2025-05-29T19:48:47.065736Z","iopub.status.idle":"2025-05-29T19:48:47.078698Z","shell.execute_reply.started":"2025-05-29T19:48:47.065711Z","shell.execute_reply":"2025-05-29T19:48:47.077613Z"}},"outputs":[{"name":"stdout","text":"Training entries: 2\nTesting entries: 1\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"### Band Score Distribution in the dataset","metadata":{}},{"cell_type":"code","source":"# def plot_band_score_distribution(dataset):\n#     \"\"\"\n#     Plot the distribution of IELTS band scores from a Dataset object.\n    \n#     Parameters:\n#     dataset (Dataset): A Hugging Face Dataset containing IELTS assessments\n#     \"\"\"\n#     # Extract band scores using regex\n#     band_scores = []\n#     for example in dataset:\n#         match = re.search(r\"Overall Band Score: (\\d+\\.?\\d*)\", example[\"output\"])\n#         if match:\n#             band_scores.append(float(match.group(1)))\n    \n#     # Create a simple histogram\n#     plt.figure(figsize=(10, 6))\n#     plt.hist(band_scores, bins=9, range=(4.5, 9), edgecolor='black')\n#     plt.title('Distribution of IELTS Band Scores')\n#     plt.xlabel('Band Score')\n#     plt.ylabel('Number of Essays')\n#     plt.xticks([4.5, 5, 5.5, 6, 6.5, 7, 7.5, 8, 8.5, 9])\n#     plt.grid(axis='y', alpha=0.75)\n#     plt.show()\n    \n#     # Print summary statistics\n#     print(f\"Average band score: {sum(band_scores)/len(band_scores):.2f}\")\n#     print(f\"Number of examples: {len(band_scores)}\")\n\n\nimport re\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef plot_band_score_distribution(dataset):\n    \"\"\"\n    Plot an aesthetically pleasing distribution of IELTS band scores.\n    \n    Parameters:\n    dataset (Dataset): A Hugging Face Dataset containing IELTS assessments\n    \"\"\"\n    # Extract band scores using regex\n    band_scores = []\n    for example in dataset:\n        match = re.search(r\"Overall Band Score: (\\d+\\.?\\d*)\", example[\"output\"])\n        if match:\n            band_scores.append(float(match.group(1)))\n    \n    # Set a clean, modern aesthetic\n    sns.set_style(\"whitegrid\")\n    plt.figure(figsize=(12, 7))\n    \n    # Create a beautiful palette\n    palette = sns.color_palette(\"viridis\", as_cmap=True)\n    \n    # Plot the distribution with enhanced aesthetics\n    ax = sns.histplot(\n        band_scores, \n        bins=9, \n        kde=True,\n        stat=\"density\",\n        alpha=0.7,\n        color=\"#3498db\",\n        edgecolor=\"white\",\n        linewidth=2,\n        kde_kws={\"color\": \"#e74c3c\", \"linewidth\": 3, \"alpha\": 0.8}\n    )\n    \n    # Add a rug plot at the bottom\n    sns.rugplot(band_scores, color=\"#2c3e50\", alpha=0.5, height=0.1, ax=ax)\n    \n    # Style the plot\n    ax.set_title('Distribution of IELTS Band Scores', fontsize=18, fontweight='bold', pad=20)\n    ax.set_xlabel('Band Score', fontsize=14, labelpad=10)\n    ax.set_ylabel('Density', fontsize=14, labelpad=10)\n    ax.set_xticks([4.5, 5, 5.5, 6, 6.5, 7, 7.5, 8, 8.5, 9])\n    ax.tick_params(labelsize=12)\n    \n    # Add mean line\n    if band_scores:\n        mean_score = np.mean(band_scores)\n        plt.axvline(x=mean_score, color='#e74c3c', linestyle='--', linewidth=2, \n                   alpha=0.7)\n        plt.text(mean_score+0.1, plt.ylim()[1]*0.9, f'Mean: {mean_score:.2f}', \n                fontsize=12, color='#e74c3c')\n    \n    # Remove top and right spines\n    sns.despine(left=False, bottom=False)\n    \n    # Add some context\n    plt.figtext(0.02, 0.02, f\"n={len(band_scores)} essays\", \n               ha=\"left\", va=\"bottom\", fontsize=10, alpha=0.7)\n    \n    # Show the plot\n    plt.tight_layout()\n    plt.show()\n    \n    # Print summary statistics\n    if band_scores:\n        print(f\"Average band score: {np.mean(band_scores):.2f}\")\n        print(f\"Median band score: {np.median(band_scores):.2f}\")\n        print(f\"Score range: {min(band_scores):.1f} - {max(band_scores):.1f}\")\n        print(f\"Number of examples: {len(band_scores)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T20:03:55.759407Z","iopub.execute_input":"2025-05-29T20:03:55.760116Z","iopub.status.idle":"2025-05-29T20:03:56.276555Z","shell.execute_reply.started":"2025-05-29T20:03:55.760076Z","shell.execute_reply":"2025-05-29T20:03:56.27462Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"plot_band_score_distribution(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T20:03:59.912851Z","iopub.execute_input":"2025-05-29T20:03:59.913706Z","iopub.status.idle":"2025-05-29T20:04:00.330845Z","shell.execute_reply.started":"2025-05-29T20:03:59.913673Z","shell.execute_reply":"2025-05-29T20:04:00.329599Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/3158595227.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_band_score_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_35/3156519879.py\u001b[0m in \u001b[0;36mplot_band_score_distribution\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Plot the distribution with enhanced aesthetics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     ax = sns.histplot(\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mband_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36mhistplot\u001b[0;34m(data, x, y, hue, weights, stat, bins, binwidth, binrange, discrete, cumulative, common_bins, common_norm, multiple, element, fill, shrink, kde, kde_kws, line_kws, thresh, pthresh, pmax, cbar, cbar_ax, cbar_kws, palette, hue_order, hue_norm, color, log_scale, legend, ax, **kwargs)\u001b[0m\n\u001b[1;32m   1430\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munivariate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m         p.plot_univariate_histogram(\n\u001b[0m\u001b[1;32m   1433\u001b[0m             \u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0melement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36mplot_univariate_histogram\u001b[0;34m(self, multiple, element, fill, common_norm, common_bins, shrink, kde, kde_kws, color, legend, line_kws, estimate_kws, **plot_kws)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mkde_kws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cumulative\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_kws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cumulative\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0mlog_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_scaled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_variable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             densities = self._compute_univariate_density(\n\u001b[0m\u001b[1;32m    452\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_variable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mcommon_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36m_compute_univariate_density\u001b[0;34m(self, data_variable, common_norm, common_grid, estimate_kws, log_scale, warn_singular)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;31m# Initialize the estimator object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKDE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mestimate_kws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: KDE.__init__() got an unexpected keyword argument 'color'"],"ename":"TypeError","evalue":"KDE.__init__() got an unexpected keyword argument 'color'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x700 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":79},{"cell_type":"markdown","source":"## Load GPT-J with Quantization for Memory Efficiency","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n\nmodel_id = \"EleutherAI/gpt-j-6B\"\n\n# Check if GPU is available\nif torch.cuda.is_available():\n    print(\"GPU detected! Using 4-bit quantization...\")\n    # Define quantization configuration\n    quantization_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_compute_dtype=torch.float16,\n        bnb_4bit_use_double_quant=True,\n        bnb_4bit_quant_type=\"nf4\"\n    )\n    \n    # Load with quantization for GPU\n    model = AutoModelForCausalLM.from_pretrained(\n        model_id,\n        quantization_config=quantization_config,\n        torch_dtype=torch.float16,\n        device_map=\"auto\"\n    )\nelse:\n    print(\"No GPU detected! For development, using a smaller model instead...\")\n    # For CPU development, consider using a much smaller model\n    # GPT-J is too large for most CPU environments\n    cpu_model_id = \"distilgpt2\"  # Only 82M parameters vs 6B\n    model = AutoModelForCausalLM.from_pretrained(\n        cpu_model_id,\n        low_cpu_mem_usage=True\n    )\n    print(f\"⚠️ NOTE: Using {cpu_model_id} instead of {model_id} for CPU development!\")\n    print(\"⚠️ Remember to switch to GPU when ready for actual fine-tuning\")\n\n# Get the tokenizer for whatever model we loaded\ntokenizer = AutoTokenizer.from_pretrained(model_id if torch.cuda.is_available() else cpu_model_id)\ntokenizer.pad_token = tokenizer.eos_token  # Set padding token\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:49:01.085793Z","iopub.execute_input":"2025-05-29T19:49:01.086181Z","iopub.status.idle":"2025-05-29T19:49:01.771272Z","shell.execute_reply.started":"2025-05-29T19:49:01.086155Z","shell.execute_reply":"2025-05-29T19:49:01.769985Z"}},"outputs":[{"name":"stdout","text":"No GPU detected! For development, using a smaller model instead...\n⚠️ NOTE: Using distilgpt2 instead of EleutherAI/gpt-j-6B for CPU development!\n⚠️ Remember to switch to GPU when ready for actual fine-tuning\n","output_type":"stream"}],"execution_count":53},{"cell_type":"markdown","source":"## Configure LoRA for Parameter-Efficient Fine-Tuning","metadata":{}},{"cell_type":"code","source":"# Inspect model architecture to find correct layer names\ndef find_target_modules(model):\n    target_modules = []\n    for name, module in model.named_modules():\n        if isinstance(module, torch.nn.Linear) and module.weight.requires_grad:\n            print(f\"Found Linear layer: {name}, Shape: {module.weight.shape}\")\n            target_modules.append(name.split('.')[-1])  # Get just the final part of the name\n    \n    # Return unique module types\n    return list(set(target_modules))\n\n# Run this to see available modules\npotential_targets = find_target_modules(model)\nprint(f\"Potential target modules: {potential_targets}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:49:05.487556Z","iopub.execute_input":"2025-05-29T19:49:05.48949Z","iopub.status.idle":"2025-05-29T19:49:05.499702Z","shell.execute_reply.started":"2025-05-29T19:49:05.489362Z","shell.execute_reply":"2025-05-29T19:49:05.497603Z"}},"outputs":[{"name":"stdout","text":"Found Linear layer: lm_head, Shape: torch.Size([50257, 768])\nPotential target modules: ['lm_head']\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"# For DistilGPT2/GPT-2 style models:\npeft_config = LoraConfig(\n    r=8,                     # Rank dimension\n    lora_alpha=32,           # Alpha parameter for LoRA scaling\n    lora_dropout=0.1,        # Dropout probability for LoRA layers\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\"c_attn\", \"c_proj\"],  # Standard GPT-2 attention layers\n)\n\n# Print configuration\nprint(f\"Using target modules for GPT-2 style architecture: ['c_attn', 'c_proj']\")\n\n# Apply LoRA to model\nmodel = get_peft_model(model, peft_config)\n\n# Print trainable parameters to verify setup\nmodel.print_trainable_parameters()\n\nprint(f\"Current model: `{model.config.model_type}` from `{model.config._name_or_path}`\")\n\n# You can also check more detailed information\nprint(\"\\nModel details:\")\nprint(f\"Architecture: {model.__class__.__name__}\")\nif hasattr(model, 'config'):\n    print(f\"Hidden size: {model.config.hidden_size}\")\n    print(f\"Vocabulary size: {model.config.vocab_size}\")\n    print(f\"Number of parameters: {(sum(p.numel() for p in model.parameters())/1000000):.2f}M\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T20:20:53.182355Z","iopub.execute_input":"2025-05-29T20:20:53.182799Z","iopub.status.idle":"2025-05-29T20:20:53.224439Z","shell.execute_reply.started":"2025-05-29T20:20:53.182767Z","shell.execute_reply":"2025-05-29T20:20:53.223306Z"}},"outputs":[{"name":"stdout","text":"Using target modules for GPT-2 style architecture: ['c_attn', 'c_proj']\ntrainable params: 405,504 || all params: 82,318,080 || trainable%: 0.4926\nCurrent model: `gpt2` from `distilgpt2`\n\nModel details:\nArchitecture: PeftModelForCausalLM\nHidden size: 768\nVocabulary size: 50257\nNumber of parameters: 82.32M\n","output_type":"stream"}],"execution_count":114},{"cell_type":"markdown","source":"## Define Training Arguments","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=10,\n    per_device_train_batch_size=1,   # Keep small due to memory constraints\n    gradient_accumulation_steps=4,   # Accumulate gradients to simulate larger batch\n    save_steps=100,\n    logging_steps=10,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    fp16=True if torch.cuda.is_available() else False, # Use mixed precision\n    report_to=\"none\",                # Disable wandb reporting\n    optim=\"adamw_torch\",\n    max_grad_norm=0.3,               # Gradient clipping\n    warmup_ratio=0.03,               # Warmup for learning rate\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:49:14.26795Z","iopub.execute_input":"2025-05-29T19:49:14.269034Z","iopub.status.idle":"2025-05-29T19:49:14.278301Z","shell.execute_reply.started":"2025-05-29T19:49:14.268993Z","shell.execute_reply":"2025-05-29T19:49:14.276599Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# class IELTSDataCollator:\n#     def __init__(self, tokenizer):\n#         self.tokenizer = tokenizer\n        \n#     def __call__(self, entries):\n#         # Extract input and output\n#         inputs = [entry[\"input\"] for entry in entries]\n#         outputs = [entry[\"output\"] for entry in entries]\n        \n#         # Format the text (input followed by output)\n#         texts = [f\"<|user|>\\n{inp}\\n<|assistant|>\\n{out}</s>\" for inp, out in zip(inputs, outputs)]\n        \n#         # Tokenize\n#         batch = self.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n        \n#         # For causal language modeling, use the input_ids as labels too\n#         batch[\"labels\"] = batch[\"input_ids\"].clone()\n        \n#         return batch\n\n# # Create the custom data collator\n# data_collator = IELTSDataCollator(tokenizer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:56:54.566366Z","iopub.execute_input":"2025-05-29T18:56:54.566677Z","iopub.status.idle":"2025-05-29T18:56:54.579683Z","shell.execute_reply.started":"2025-05-29T18:56:54.566648Z","shell.execute_reply":"2025-05-29T18:56:54.578606Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Set Up Trainer and Start Fine-Tuning","metadata":{}},{"cell_type":"code","source":"model.config.model_type","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T20:18:45.171338Z","iopub.execute_input":"2025-05-29T20:18:45.171843Z","iopub.status.idle":"2025-05-29T20:18:45.178791Z","shell.execute_reply.started":"2025-05-29T20:18:45.171806Z","shell.execute_reply":"2025-05-29T20:18:45.177681Z"}},"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"'gpt2'"},"metadata":{}}],"execution_count":106},{"cell_type":"code","source":"model.base_model.config._name_or_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T20:16:58.476644Z","iopub.execute_input":"2025-05-29T20:16:58.477098Z","iopub.status.idle":"2025-05-29T20:16:58.483354Z","shell.execute_reply.started":"2025-05-29T20:16:58.477072Z","shell.execute_reply":"2025-05-29T20:16:58.482127Z"}},"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"'distilgpt2'"},"metadata":{}}],"execution_count":100},{"cell_type":"code","source":"model.__dict__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T20:13:55.437512Z","iopub.execute_input":"2025-05-29T20:13:55.438197Z","iopub.status.idle":"2025-05-29T20:13:55.448478Z","shell.execute_reply.started":"2025-05-29T20:13:55.438168Z","shell.execute_reply":"2025-05-29T20:13:55.44742Z"}},"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"{'training': True,\n '_parameters': {},\n '_buffers': {},\n '_non_persistent_buffers_set': set(),\n '_backward_pre_hooks': OrderedDict(),\n '_backward_hooks': OrderedDict(),\n '_is_full_backward_hook': None,\n '_forward_hooks': OrderedDict(),\n '_forward_hooks_with_kwargs': OrderedDict(),\n '_forward_hooks_always_called': OrderedDict(),\n '_forward_pre_hooks': OrderedDict(),\n '_forward_pre_hooks_with_kwargs': OrderedDict(),\n '_state_dict_hooks': OrderedDict(),\n '_state_dict_pre_hooks': OrderedDict(),\n '_load_state_dict_pre_hooks': OrderedDict(),\n '_load_state_dict_post_hooks': OrderedDict(),\n '_modules': {'base_model': LoraModel(\n    (model): GPT2LMHeadModel(\n      (transformer): GPT2Model(\n        (wte): Embedding(50257, 768)\n        (wpe): Embedding(1024, 768)\n        (drop): Dropout(p=0.1, inplace=False)\n        (h): ModuleList(\n          (0-5): 6 x GPT2Block(\n            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): GPT2Attention(\n              (c_attn): lora.Linear(\n                (base_layer): Conv1D(nf=2304, nx=768)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=2304, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (c_proj): lora.Linear(\n                (base_layer): Conv1D(nf=768, nx=768)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (attn_dropout): Dropout(p=0.1, inplace=False)\n              (resid_dropout): Dropout(p=0.1, inplace=False)\n            )\n            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): GPT2MLP(\n              (c_fc): Conv1D(nf=3072, nx=768)\n              (c_proj): lora.Linear(\n                (base_layer): Conv1D(nf=768, nx=3072)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3072, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act): NewGELUActivation()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n    )\n  )},\n 'modules_to_save': None,\n 'active_adapter': 'default',\n 'peft_type': <PeftType.LORA: 'LORA'>,\n 'special_peft_forward_args': {'adapter_names'},\n '_is_prompt_learning': False,\n '_peft_config': None,\n 'base_model_prepare_inputs_for_generation': <bound method GenerationMixin.prepare_inputs_for_generation of GPT2LMHeadModel(\n   (transformer): GPT2Model(\n     (wte): Embedding(50257, 768)\n     (wpe): Embedding(1024, 768)\n     (drop): Dropout(p=0.1, inplace=False)\n     (h): ModuleList(\n       (0-5): 6 x GPT2Block(\n         (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n         (attn): GPT2Attention(\n           (c_attn): lora.Linear(\n             (base_layer): Conv1D(nf=2304, nx=768)\n             (lora_dropout): ModuleDict(\n               (default): Dropout(p=0.1, inplace=False)\n             )\n             (lora_A): ModuleDict(\n               (default): Linear(in_features=768, out_features=8, bias=False)\n             )\n             (lora_B): ModuleDict(\n               (default): Linear(in_features=8, out_features=2304, bias=False)\n             )\n             (lora_embedding_A): ParameterDict()\n             (lora_embedding_B): ParameterDict()\n             (lora_magnitude_vector): ModuleDict()\n           )\n           (c_proj): lora.Linear(\n             (base_layer): Conv1D(nf=768, nx=768)\n             (lora_dropout): ModuleDict(\n               (default): Dropout(p=0.1, inplace=False)\n             )\n             (lora_A): ModuleDict(\n               (default): Linear(in_features=768, out_features=8, bias=False)\n             )\n             (lora_B): ModuleDict(\n               (default): Linear(in_features=8, out_features=768, bias=False)\n             )\n             (lora_embedding_A): ParameterDict()\n             (lora_embedding_B): ParameterDict()\n             (lora_magnitude_vector): ModuleDict()\n           )\n           (attn_dropout): Dropout(p=0.1, inplace=False)\n           (resid_dropout): Dropout(p=0.1, inplace=False)\n         )\n         (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n         (mlp): GPT2MLP(\n           (c_fc): Conv1D(nf=3072, nx=768)\n           (c_proj): lora.Linear(\n             (base_layer): Conv1D(nf=768, nx=3072)\n             (lora_dropout): ModuleDict(\n               (default): Dropout(p=0.1, inplace=False)\n             )\n             (lora_A): ModuleDict(\n               (default): Linear(in_features=3072, out_features=8, bias=False)\n             )\n             (lora_B): ModuleDict(\n               (default): Linear(in_features=8, out_features=768, bias=False)\n             )\n             (lora_embedding_A): ParameterDict()\n             (lora_embedding_B): ParameterDict()\n             (lora_magnitude_vector): ModuleDict()\n           )\n           (act): NewGELUActivation()\n           (dropout): Dropout(p=0.1, inplace=False)\n         )\n       )\n     )\n     (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n   )\n   (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n )>,\n '_is_accelerate_prepared': True}"},"metadata":{}}],"execution_count":95},{"cell_type":"code","source":"def preprocess_function(entries):\n    # Format the text\n    texts = [\n        f\"<|user|>\\n{entries['input'][i]}\\n<|assistant|>\\n{entries['output'][i]}</s>\"\n        for i in range(len(entries['input']))\n    ]\n    \n    # Tokenize\n    tokenized = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=512)\n    \n    # For language modeling\n    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n    \n    return tokenized\n\n# Process the dataset\nprocessed_dataset = train_dataset.map(\n    preprocess_function, \n    batched=True,\n    remove_columns=train_dataset.column_names  # Remove the original columns\n)\n\n# Define the Trainer with processed dataset\ntrainer = Trainer(\n    model=model,\n    args=training_args,  # No need for remove_unused_columns=False here\n    train_dataset=processed_dataset,\n    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T20:19:48.378822Z","iopub.execute_input":"2025-05-29T20:19:48.379202Z","iopub.status.idle":"2025-05-29T20:19:48.467352Z","shell.execute_reply.started":"2025-05-29T20:19:48.379178Z","shell.execute_reply":"2025-05-29T20:19:48.466324Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c217e97c167b4a6dbe8f3688af8b0f07"}},"metadata":{}},{"name":"stderr","text":"No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":111},{"cell_type":"code","source":"# Start training\ntrainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Data collator\n# data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n\n# # Define custom data formatting function\n# def formatting_func(entries):\n#     texts = []\n#     for i in range(len(entries[\"input\"])):\n#         text = f\"<|user|>\\n{entries['input'][i]}\\n<|assistant|>\\n{entries['output'][i]}</s>\"\n#         texts.append(text)\n#     return texts\n\n# # Define the Trainer\n# trainer = Trainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=train_dataset,\n#     tokenizer=tokenizer,\n#     data_collator=data_collator,\n# )\n\n# # Start training\n# trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:02.380457Z","iopub.execute_input":"2025-05-29T18:57:02.380782Z","iopub.status.idle":"2025-05-29T18:57:02.385404Z","shell.execute_reply.started":"2025-05-29T18:57:02.380759Z","shell.execute_reply":"2025-05-29T18:57:02.384521Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Save the Fine-Tuned Model","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the model (just the LoRA weights, not the full model)\nmodel.save_pretrained(\"./pretrained_gptj\")\ntokenizer.save_pretrained(\"./pretrained_gptj\")\n\n# Download the model to the local machine\nfrom IPython.display import FileLinks\nFileLinks(r'./pretrained_gptj')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:50:10.248117Z","iopub.execute_input":"2025-05-29T19:50:10.248602Z","iopub.status.idle":"2025-05-29T19:50:10.672395Z","shell.execute_reply.started":"2025-05-29T19:50:10.248545Z","shell.execute_reply":"2025-05-29T19:50:10.670505Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"./pretrained_gptj/\n  vocab.json\n  merges.txt\n  adapter_model.safetensors\n  tokenizer_config.json\n  adapter_config.json\n  tokenizer.json\n  special_tokens_map.json\n  README.md","text/html":"./pretrained_gptj/<br>\n&nbsp;&nbsp;<a href='./pretrained_gptj/vocab.json' target='_blank'>vocab.json</a><br>\n&nbsp;&nbsp;<a href='./pretrained_gptj/merges.txt' target='_blank'>merges.txt</a><br>\n&nbsp;&nbsp;<a href='./pretrained_gptj/adapter_model.safetensors' target='_blank'>adapter_model.safetensors</a><br>\n&nbsp;&nbsp;<a href='./pretrained_gptj/tokenizer_config.json' target='_blank'>tokenizer_config.json</a><br>\n&nbsp;&nbsp;<a href='./pretrained_gptj/adapter_config.json' target='_blank'>adapter_config.json</a><br>\n&nbsp;&nbsp;<a href='./pretrained_gptj/tokenizer.json' target='_blank'>tokenizer.json</a><br>\n&nbsp;&nbsp;<a href='./pretrained_gptj/special_tokens_map.json' target='_blank'>special_tokens_map.json</a><br>\n&nbsp;&nbsp;<a href='./pretrained_gptj/README.md' target='_blank'>README.md</a><br>"},"metadata":{}}],"execution_count":59},{"cell_type":"markdown","source":"### Zip into a file\nFor downloading in case running on online platform like Kaggle","metadata":{}},{"cell_type":"code","source":"# Create a zip file of the model directory\n!zip -r pretrained_gptj.zip ./pretrained_gptj\n\n# Create a download link for the zip file\nfrom IPython.display import FileLink\nFileLink(\"pretrained_gptj.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:50:12.889765Z","iopub.execute_input":"2025-05-29T19:50:12.890151Z","iopub.status.idle":"2025-05-29T19:50:13.531635Z","shell.execute_reply.started":"2025-05-29T19:50:12.890126Z","shell.execute_reply":"2025-05-29T19:50:13.530088Z"}},"outputs":[{"name":"stdout","text":"updating: pretrained_gptj/ (stored 0%)\nupdating: pretrained_gptj/vocab.json (deflated 59%)\nupdating: pretrained_gptj/merges.txt","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 53%)\nupdating: pretrained_gptj/adapter_model.safetensors (deflated 8%)\nupdating: pretrained_gptj/tokenizer_config.json (deflated 54%)\nupdating: pretrained_gptj/adapter_config.json (deflated 55%)\nupdating: pretrained_gptj/tokenizer.json (deflated 82%)\nupdating: pretrained_gptj/special_tokens_map.json (deflated 60%)\nupdating: pretrained_gptj/README.md (deflated 66%)\n","output_type":"stream"},{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/pretrained_gptj.zip","text/html":"<a href='pretrained_gptj.zip' target='_blank'>pretrained_gptj.zip</a><br>"},"metadata":{}}],"execution_count":60},{"cell_type":"markdown","source":"## Load Model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nfrom peft import PeftModel, PeftConfig\n\n# Load the base model first\nbase_model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\")\n\n# Load your fine-tuned LoRA weights\npeft_model_id = \"./downloaded_location/pretrained_gptj\"\nmodel = PeftModel.from_pretrained(base_model, peft_model_id)\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n\n# Your model is ready to use!\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Test the Fine-Tuned Model","metadata":{}},{"cell_type":"code","source":"# Test the model on an entry\ns = \"Rate this IELTS essay: In some countries, young people are encouraged to work or travel for a year between finishing high school and starting university studies. Discuss the advantages and disadvantages for young people who decide to do this.\"\n\ninputs = tokenizer(test_input, return_tensors=\"pt\").to(\"cuda\")\noutput = model.generate(\n    inputs.input_ids,\n    max_new_tokens=512,\n    temperature=0.7,\n    top_p=0.9,\n    repetition_penalty=1.2\n)\n\nprint(tokenizer.decode(output[0], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T18:57:03.43581Z","iopub.status.idle":"2025-05-29T18:57:03.436261Z","shell.execute_reply.started":"2025-05-29T18:57:03.436097Z","shell.execute_reply":"2025-05-29T18:57:03.436117Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_input = test_dataset['input'][0]\n\ninputs = tokenizer(test_input, return_tensors=\"pt\").to(\"cuda\")\noutput = model.generate(\n    inputs.input_ids,\n    max_new_tokens=512,\n    temperature=0.7,\n    top_p=0.9,\n    repetition_penalty=1.2\n)\n\nprint(tokenizer.decode(output[0], skip_special_tokens=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:52:06.413193Z","iopub.execute_input":"2025-05-29T19:52:06.414701Z","iopub.status.idle":"2025-05-29T19:52:06.483184Z","shell.execute_reply.started":"2025-05-29T19:52:06.414657Z","shell.execute_reply":"2025-05-29T19:52:06.481008Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/431000092.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m output = model.generate(\n\u001b[1;32m      5\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, device, non_blocking)\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;31m# into a HalfTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m             self.data = {\n\u001b[0m\u001b[1;32m    821\u001b[0m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m             self.data = {\n\u001b[0;32m--> 821\u001b[0;31m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m             }\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"],"ename":"RuntimeError","evalue":"Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx","output_type":"error"}],"execution_count":68}]}